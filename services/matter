#!/usr/bin/python

import sys
import os
import shlex
import signal
import argparse
import tempfile
import subprocess
import errno

# Entropy imports
sys.path.insert(0,'/usr/lib/entropy/libraries')
sys.path.insert(0,'/usr/lib/entropy/server')
sys.path.insert(0,'/usr/lib/entropy/client')
sys.path.insert(0,'../libraries')
sys.path.insert(0,'../server')
sys.path.insert(0,'../client')

# Entropy imports
from entropy.exceptions import PermissionDenied
from entropy.const import etpConst, etpUi, const_convert_to_unicode, \
    const_get_stringtype
from entropy.output import print_info, print_error, print_warning, \
    purple, darkgreen
from entropy.exceptions import InvalidAtom, SPMError
from entropy.server.interfaces import Server

import entropy.tools
import entropy.dep

# Portage imports
import portage
import portage.versions

from _emerge.depgraph import backtrack_depgraph
from _emerge.actions import load_emerge_config, action_build
from _emerge.create_depgraph_params import create_depgraph_params
from _emerge.main import parse_opts, post_emerge, \
    validate_ebuild_environment
from _emerge.stdout_spinner import stdout_spinner


def get_entropy_server(community_mode):
    """
    Return Entropy Server interface object.
    """
    return Server(community_repo = community_mode)

def exec_cmd(args, env = None):
    """
    Execute a command with given environment.
    """
    pid = os.fork()
    if pid == 0:
        if env is not None:
            os.execvpe(args[0], args, env)
        else:
            os.execvp(args[0], args)
    else:
        try:
            rcpid, rc = os.waitpid(pid, 0)
        except KeyboardInterrupt:
            rc = 1
            os.kill(pid, signal.SIGTERM)
        return rc



class EntropyResourceLock(object):
    """
    This class exposes a Lock-like interface for acquiring Entropy Server
    resources.
    """

    class NotAcquired(Exception):
        """ Raised when Entropy Resource Lock cannot be acquired """

    def __init__(self, entropy_server, blocking):
        """
        EntropyResourceLock constructor.

        @param entropy_server: Entropy Server instance
        @type entropy_server: entropy.server.interfaces.Server
        @param blocking: acquire lock in blocking mode?
        @type blocking: bool
        """
        self._entropy = entropy_server
        self._blocking = blocking
        self.__inside_with_stmt = 0

    def acquire(self):
        acquired = entropy.tools.acquire_entropy_resources_locks(self._entropy,
            blocking = self._blocking)
        if not acquired:
            raise EntropyResourceLock.NotAcquired("unable to acquire lock")

    def release(self):
        entropy.tools.release_entropy_locks(self._entropy)

    def __enter__(self):
        """
        Acquire lock. Not thread-safe.
        """
        if self.__inside_with_stmt < 1:
            self.acquire()
        self.__inside_with_stmt += 1
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        """
        Release lock. Not thread-safe.
        """
        self.__inside_with_stmt -= 1
        if self.__inside_with_stmt < 1:
            self.release()

class GenericSpecFunctions(object):

    def ne_string(self, x):
        return x, 'raw_unicode_escape'

    def ne_list(self, x):
        return x

    def not_none(self, x):
        return x is not None

    def valid_integer(self, x):
        try:
            int(x)
        except (TypeError, ValueError,):
            return False
        return True

    def always_valid(self, *args):
        return True

    def valid_path(self, x):
        return os.path.lexists(x)

    def valid_file(self, x):
        return os.path.isfile(x)

    def valid_dir(self, x):
        return os.path.isdir(x)

    def ve_string_open_file_read(self, x):
        try:
            return open(x, "r")
        except (IOError, OSError):
            return None

    def ve_string_stripper(self, x):
        return const_convert_to_unicode(x).strip()

    def ve_string_splitter(self, x):
        return const_convert_to_unicode(x).strip().split()

    def ve_integer_converter(self, x):
        return int(x)

    def valid_ascii(self, x):
        try:
            x = str(x)
            return x
        except (UnicodeDecodeError, UnicodeEncodeError,):
            return ''

    def valid_yes_no(self, x):
        return x in ("yes", "no")

    def valid_path_string(self, x):
        try:
            os.path.split(x)
        except OSError:
            return False
        return True

    def valid_path_string_first_list_item(self, x):
        if not x:
            return False
        myx = x[0]
        try:
            os.path.split(myx)
        except OSError:
            return False
        return True

    def valid_comma_sep_list(self, x):
        return [y.strip() for y in \
            const_convert_to_unicode(x).split(",") if y.strip()]

    def valid_path_list(self, x):
        return [y.strip() for y in \
            const_convert_to_unicode(x).split(",") if \
                self.valid_path_string(y) and y.strip()]

class MatterSpec(GenericSpecFunctions):

    def vital_parameters(self):
        """
        Return a list of vital .spec file parameters

        @return: list of vital .spec file parameters
        @rtype: list
        """
        return ["packages", "repository"]

    def parser_data_path(self):
        """
        Return a dictionary containing parameter names as key and
        dict containing keys 've' and 'cb' which values are three
        callable functions that respectively do value extraction (ve),
        value verification (cb) and value modding (mod).

        @return: data path dictionary (see ChrootSpec code for more info)
        @rtype: dict
        """
        return {
            'dependencies': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'downgrade': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'keep-going': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'new-useflags': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'removed-useflags': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'rebuild': {
                'cb': self.valid_yes_no,
                've': self.ve_string_stripper,
            },
            'pkgpre': {
                'cb': self.not_none,
                've': self.ve_string_open_file_read,
            },
            'pkgpost': {
                'cb': self.not_none,
                've': self.ve_string_open_file_read,
            },
            'packages': {
                'cb': self.always_valid,
                've': self.valid_comma_sep_list,
            },
            'repository': {
                'cb': self.ne_string,
                've': self.ve_string_stripper,
            },
        }


class SpecPreprocessor:

    PREFIX = "%"
    class PreprocessorError(Exception):
        """ Error while preprocessing file """

    def __init__(self, spec_file_obj):
        self.__expanders = {}
        self.__builtin_expanders = {}
        self._spec_file_obj = spec_file_obj
        self._add_builtin_expanders()

    def add_expander(self, statement, expander_callback):
        """
        Add Preprocessor expander.

        @param statement: statement to expand
        @type statement: string
        @param expand_callback: one argument callback that is used to expand
            given line (line is raw format). Line is already pre-parsed and
            contains a valid preprocessor statement that callback can handle.
            Preprocessor callback should raise SpecPreprocessor.PreprocessorError
            if line is malformed.
        @type expander_callback: callable
        @raise KeyError: if expander is already available
        @return: a raw string (containing \n and whatever)
        @rtype: string
        """
        return self._add_expander(statement, expander_callback, builtin = False)

    def _add_expander(self, statement, expander_callback, builtin = False):
        obj = self.__expanders
        if builtin:
            obj = self.__builtin_expanders
        if statement in obj:
            raise KeyError("expander %s already provided" % (statement,))
        obj[SpecPreprocessor.PREFIX + statement] = \
            expander_callback

    def _add_builtin_expanders(self):
        # import statement
        self._add_expander("import", self._import_expander, builtin = True)

    def _import_expander(self, line):

        rest_line = line.split(" ", 1)[1].strip()
        if not rest_line:
            return line

        spec_f = self._spec_file_obj
        spec_f.seek(0)
        lines = ''
        try:
            for line in spec_f.readlines():
                # call recursively
                split_line = line.split(" ", 1)
                if split_line:
                    expander = self.__builtin_expanders.get(split_line[0])
                    if expander is not None:
                        try:
                            line = expander(line)
                        except RuntimeError as err:
                            raise SpecPreprocessor.PreprocessorError(
                                "invalid preprocessor line: %s" % (err,))
                lines += line
        finally:
            spec_f.seek(0)

        return lines

    def parse(self):

        content = []
        spec_f = self._spec_file_obj
        spec_f.seek(0)

        try:
            for line in spec_f.readlines():
                split_line = line.split(" ", 1)
                if split_line:
                    expander = self.__builtin_expanders.get(split_line[0])
                    if expander is not None:
                        line = expander(line)
                content.append(line)
        finally:
            spec_f.seek(0)

        final_content = []
        for line in content:
            split_line = line.split(" ", 1)
            if split_line:
                expander = self.__expanders.get(split_line[0])
                if expander is not None:
                    line = expander(line)
            final_content.append(line)

        final_content = (''.join(final_content)).split("\n")

        return final_content


class SpecParser:

    def __init__(self, file_object):

        self.file_object = file_object
        self._preprocessor = SpecPreprocessor(self.file_object)

        self.__plugin = MatterSpec()
        self.vital_parameters = self.__plugin.vital_parameters()
        self.parser_data_path = self.__plugin.parser_data_path()

    def _parse_line_statement(self, line_stmt):
        try:
            key, value = line_stmt.split(":", 1)
        except ValueError:
            return None, None
        key, value = key.strip(), value.strip()
        return key, value

    def parse(self):
        mydict = {}
        data = self._generic_parser()
        # compact lines properly
        old_key = None
        for line in data:
            key = None
            value = None
            v_key, v_value = self._parse_line_statement(line)
            check_dict = self.parser_data_path.get(v_key)
            if check_dict is not None:
                key, value = v_key, v_value
                old_key = key
            elif isinstance(old_key, const_get_stringtype()):
                key = old_key
                value = line.strip()
                if not value:
                    continue
            # gather again... key is changed
            check_dict = self.parser_data_path.get(key)
            if not isinstance(check_dict, dict):
                continue
            value = check_dict['ve'](value)
            if not check_dict['cb'](value):
                continue
            if key in mydict:
                if isinstance(value, const_get_stringtype()):
                    mydict[key] += " %s" % (value,)
                elif isinstance(value, list):
                    mydict[key] += value
                else:
                    continue
            else:
                mydict[key] = value
        self.validate_parse(mydict)
        return mydict.copy()

    def validate_parse(self, mydata):
        for param in self.vital_parameters:
            if param not in mydata:
                raise ValueError(
                    "'%s' missing or invalid"
                    " '%s' parameter, it's vital. Your specification"
                    " file is incomplete!" % (self.file_object.name, param,)
                )

    def _generic_parser(self):
        data = []
        content = self._preprocessor.parse()
        # filter comments and white lines
        content = [x.strip().rsplit("#", 1)[0].strip() for x in content if \
            not x.startswith("#") and x.strip()]
        for line in content:
            if line in data:
                continue
            data.append(line)
        return data


class PackageBuilder(object):
    """
    Portage Package builder class
    """

    DEFAULT_PORTAGE_SYNC_CMD = "emerge --sync"
    PORTAGE_SYNC_CMD = shlex.split(os.getenv("MATTER_PORTAGE_SYNC_CMD",
        DEFAULT_PORTAGE_SYNC_CMD))

    DEFAULT_OVERLAYS_SYNC_CMD = "layman -S"
    OVERLAYS_SYNC_CMD = shlex.split(os.getenv("MATTER_OVERLAYS_SYNC_CMD",
        DEFAULT_OVERLAYS_SYNC_CMD))

    DEFAULT_PORTAGE_BUILD_ARGS = "--verbose --nospinner"
    PORTAGE_BUILD_ARGS = os.getenv("MATTER_PORTAGE_BUILD_ARGS",
        DEFAULT_PORTAGE_BUILD_ARGS).split()

    def __init__(self, entropy_server, package, params):
        self._entropy = entropy_server
        self._package = package
        self._params = params

    @staticmethod
    def _build_standard_environment(repository=None):
        env = os.environ.copy()
        if repository is not None:
            env["MATTER_REPOSITORY_ID"] = repository
        return env

    @staticmethod
    def setup(executable_hook_f, cwd):
        hook_name = executable_hook_f.name
        if not hook_name.endswith("/"):
            # complete with current directory
            hook_name = os.path.join(cwd, hook_name)

        print_info("spawning pre hook: %s" % (hook_name,))
        return exec_cmd([hook_name],
            env = PackageBuilder._build_standard_environment())

    @staticmethod
    def teardown(executable_hook_f, cwd, exit_st):
        hook_name = executable_hook_f.name
        if not hook_name.endswith("/"):
            # complete with current directory
            hook_name = os.path.join(cwd, hook_name)

        print_info("spawning post hook: %s, passing exit status: %d" % (
            hook_name, exit_st,))
        env = PackageBuilder._build_standard_environment()
        env["MATTER_EXIT_STATUS"] = str(exit_st)
        return exec_cmd([hook_name], env = env)

    def run(self):
        """
        Execute Package building action.
        """
        print_info(
            "spawning package build: %s" % (self._package,))

        # ignore exit status
        subprocess.call(["env-update"])

        std_env = PackageBuilder._build_standard_environment(
            repository=self._params["repository"])
        std_env["MATTER_PACKAGE_NAME"] = self._package
        print_info("MATTER_PACKAGE_NAME = %s" % (self._package,))

        # run pkgpre, if any
        pkgpre = self._params.get("pkgpre")
        if pkgpre is not None:
            print_info(
                "spawning --pkgpre: %s, name: %s" % (pkgpre, pkgpre.name))
            tmp_fd, tmp_path = tempfile.mkstemp(prefix="matter")
            with os.fdopen(tmp_fd, "wb") as tmp_f:
                tmp_f.write(pkgpre.read())
            try:
                # now execute
                os.chmod(tmp_path, 0o700)
                exit_st = exec_cmd([tmp_path], env = std_env)
                if exit_st != 0:
                    return exit_st
            finally:
                os.remove(tmp_path)

        # execute the update code
        exit_st = self._run_builder(std_env)
        if exit_st != 0:
            return exit_st

        # run pkgpre, if any
        pkgpost = self._params.get("pkgpost")
        if pkgpost is not None:
            print_info(
                "spawning --pkgpost: %s, name: %s" % (pkgpost, pkgpost.name))
            tmp_fd, tmp_path = tempfile.mkstemp(prefix="matter")
            with os.fdopen(tmp_fd, "wb") as tmp_f:
                tmp_f.write(pkgpost.read())
            try:
                # now execute
                os.chmod(tmp_path, 0o700)
                exit_st = exec_cmd([tmp_path], env = std_env)
                if exit_st != 0:
                    return exit_st
            finally:
                os.remove(tmp_path)

        # so far, so good
        return 0

    def _run_builder(self, env):
        """
        This method is called by _run and executes the whole package build
        logic, including constraints validation given by argv parameters.
        NOTE: negative errors indicate warnings that can be skipped.
        """
        portdb = portage.portdb
        portdb.freeze()
        settings = portage.config(clone=portage.settings)
        vardb = portage.db[settings["ROOT"]]["vartree"].dbapi
        fakedb = portage.fakedbapi(settings=portage.settings)

        # Load the most current variables from /etc/profile.env, which
        # has been re-generated by the env-update call in _run()
        settings.unlock()
        settings.reload()
        settings.regenerate()
        settings.lock()

        best_visible = portdb.xmatch("bestmatch-visible", self._package)
        if not best_visible:
            # package not found, return error
            print_error("cannot match: %s, aborting" % (self._package,))
            return 1

        print_info("matched: %s for %s" % (best_visible, self._package,))
        # now determine what's the installed version.
        best_installed = portage.best(vardb.match(self._package))
        if not best_installed:
            # package not installed, behaviour not supported atm
            print_error("package not installed: %s, aborting" % (
                self._package,))
            return 1

        print_info("found installed: %s for %s" % (best_installed,
            self._package,))

        # now compare
        # -1 if best_installed is older than best_visible
        # 1 if best_installed is newer than best_visible
        # 0 if they are equal
        cmp_res = portage.versions.pkgcmp(
            portage.versions.pkgsplit(best_installed),
            portage.versions.pkgsplit(best_visible))

        if (cmp_res == 1) and (self._params.get("downgrade", "no") == "no"):
            # downgrade in action and downgrade not allowed, aborting!
            print_error(
                "package: %s, would be downgraded from %s to %s, aborting" % (
                    self._package, best_installed, best_visible,))
            return -1

        if (cmp_res == 0) and (self._params.get("rebuild", "no") == "no"):
            # rebuild in action and rebuild not allowed, aborting!
            print_error(
                "package: %s, would be rebuilt to %s, aborting" % (
                    self._package, best_visible,))
            return -1

        # at this point we can go ahead building self._package
        print_info("starting to build: %s, to %s" % (self._package,
            best_visible,))

        print_info("portage modules loaded with success")

        emerge_settings, emerge_trees, mtimedb = \
            load_emerge_config(trees=portage.db)
        # non interactive properties
        builtin_args = ["--accept-properties=-interactive"]
        myaction, myopts, myfiles = parse_opts(
            PackageBuilder.PORTAGE_BUILD_ARGS + builtin_args + \
                ["="+best_visible])
        if "--pretend" in myopts:
            print_warning("cannot use --pretend emerge argument, you idiot")
            del myopts["--pretend"]
        if "--ask" in myopts:
            print_warning("cannot use --ask emerge argument, you idiot")
            del myopts["--ask"]
        spinner = None
        if ("--quiet" not in myopts) or ("--nospinner" in myopts):
            spinner = stdout_spinner()
        params = create_depgraph_params(myopts, myaction)
        success, graph, favorites = backtrack_depgraph(emerge_settings,
            emerge_trees, myopts, params, myaction, myfiles, spinner)

        if not success:
            # print issues to stdout and give up
            print_error("dependencies calculation failed for %s, aborting" % (
                best_visible,))
            graph.display_problems()
            return -1
        print_info("dependency graph generated successfully")

        # list of _emerge.Package.Package objects
        package_queue = graph.altlist()
        dep_list = [p.cpv+"::"+p.repo for p in package_queue]

        # calculate dependencies, if --dependencies is not enabled
        # because we have to validate it
        if (self._params.get("dependencies", "no") == "no") \
                and (len(package_queue) > 1):
            # package is pulling in dependencies, but --dependencies is not
            # enabled. need to give up
            deps = ", ".join(dep_list)
            print_error(
                "package %s is pulling in: %s, but --dependencies "
                "not specified, aborting" % (best_visible, deps,))
            return -1

        # inspect use flags changes
        allow_new_useflags = self._params.get("new-useflags", "no") == "yes"
        allow_removed_useflags = \
            self._params.get("removed-useflags", "no") == "yes"

        use_flags_give_up = False
        if (not allow_new_useflags) or (not allow_removed_useflags):
            # checking for use flag changes
            for pkg in package_queue:
                # frozenset
                enabled_flags = pkg.use.enabled
                inst_atom = portage.best(vardb.match(pkg.slot_atom))
                if not inst_atom:
                    # new package, ignore check
                    continue
                installed_flags = frozenset(
                    vardb.aux_get(inst_atom, ["USE"])[0].split())

                new_flags = enabled_flags - installed_flags
                removed_flags = installed_flags - enabled_flags

                if (not allow_new_useflags) and new_flags:
                    print_error("ouch: %s wants these new USE flags: %s" % (
                        p.cpv+"::"+p.repo, " ".join(sorted(new_flags)),))
                    use_flags_give_up = True
                if (not allow_removed_useflags) and removed_flags:
                    print_error("ouch: %s has these USE flags removed: %s" % (
                        p.cpv+"::"+p.repo, " ".join(sorted(removed_flags)),))
                    use_flags_give_up = True

        if use_flags_give_up:
            print_error("cannot continue due to unmet USE flags constraint")
            return -1

        print_info("USE flags constraints are met for all the queued packages")
        print_info("about to build the following packages:")
        for dep in dep_list:
            print_info("  %s" % (dep,))

        # re-calling action_build(), deps are re-calculated though
        validate_ebuild_environment(emerge_trees)
        retval = action_build(emerge_settings, emerge_trees, mtimedb,
            myopts, myaction, myfiles, spinner)

        # NOTE: this is a WORKAROUND for Portage's post_emerge() calling
        # sys.exit() at the end.
        sys_exit = sys.exit
        sys.exit = lambda x: None
        post_emerge(myaction, myopts, myfiles, emerge_settings["ROOT"],
            emerge_trees, mtimedb, retval)
        sys.exit = sys_exit

        print_info("portage spawned, return value: %d" % (retval,))

        return retval

    @staticmethod
    def sync():
        """
        Execute Portage and Overlays sync
        """
        sync_cmd = PackageBuilder.PORTAGE_SYNC_CMD
        std_env = PackageBuilder._build_standard_environment()
        rc = exec_cmd(sync_cmd, env = std_env)
        if rc != 0:
            return rc

        # overlays update
        overlay_cmd = PackageBuilder.OVERLAYS_SYNC_CMD
        return exec_cmd(overlay_cmd, env = std_env)

    @staticmethod
    def check_preserved_libraries():
        """
        Ask portage whether there are preserved libraries on the system.
        This usually indicates that Entropy packages should not be really
        committed.

        @return: True, if preserved libraries are found
        @rtype: bool
        """
        import portage
        settings = portage.config(clone=portage.settings)
        vardb = portage.db[settings["ROOT"]]["vartree"].dbapi
        vardb._plib_registry.load()
        return vardb._plib_registry.hasEntries()

    @staticmethod
    def commit(entropy_server, repository, packages):
        """
        Commit packages to Entropy repository.
        """
        spm = entropy_server.Spm()
        spm_atoms = set()
        exit_st = 0

        print_info("committing packages: %s, to repository: %s" % (
            ", ".join(sorted(packages)), repository,))

        # if we get here, something has been compiled
        # successfully
        for package in completed:
            try:
                spm_atom = spm.match_installed_package(package)
                spm_atoms.add(spm_atom)
            except InvalidAtom:
                exit_st = 1
                print_warning(
                    "cannot find installed package: %s" % (
                        package,))
                continue

        if not spm_atoms:
            return exit_st

        print_info("about to commit:")
        spm_packages = sorted(spm_atoms)

        for atom in spm_packages:
            item_txt = atom

            # this is a spm atom
            spm_key = entropy.dep.dep_getkey(atom)
            try:
                spm_slot = spm.get_installed_package_metadata(
                    atom, "SLOT")
                spm_repo = spm.get_installed_package_metadata(
                    atom, "repository")
            except KeyError:
                spm_slot = None
                spm_repo = None

            etp_repo = None
            if spm_repo is not None:
                pkg_id, repo_id = entropy_server.atom_match(spm_key,
                    match_slot = spm_slot)
                if repo_id != 1:
                    repo_db = entropy_server.open_repository(repo_id)
                    etp_repo = repo_db.retrieveSpmRepository(pkg_id)

                    if (etp_repo is not None) and (etp_repo != spm_repo):
                        item_txt += ' [%s {%s=>%s}]' % ("warning",
                            etp_repo, spm_repo,)

            print_info(item_txt)

        # always stuff new configuration files here
        # if --gentle was specified, the uncommitted stuff here belongs
        # to our packages.
        # if --gentle was NOT specified, we just don't give a shit
        uncommitted = entropy_server._check_config_file_updates()
        if uncommitted:
            subprocess.call("echo -5 | etc-update", shell = True)
        # test again
        uncommitted = entropy_server._check_config_file_updates()
        if uncommitted:
            # ouch, wtf? better aborting
            print_error("tried to commit configuration file changes and failed")
            return 1

        print_info("about to compress:")

        store_dir = entropy_server._get_local_store_directory(repository)
        package_paths = []
        for atom in spm_packages:
            print_info(atom)
            try:
                package_path = spm.generate_package(atom, store_dir)
            except OSError:
                entropy.tools.print_traceback()
                print_error("problem during package generation, aborting")
                return 1
            except SPMError:
                entropy.tools.print_traceback()
                print_error("problem during package generation (2), aborting")
                return 1
            package_paths.append(package_path)

        etp_pkg_files = [(x, False) for x in package_paths]
        # NOTE: any missing runtime dependency will be added
        # (beside those blacklisted), since this execution is not interactive
        package_ids = entropy_server.add_packages_to_repository(
            repository, etp_pkg_files, ask = False)
        if package_ids:
            # checking dependencies and print issues
            entropy_server.dependencies_test(repository)
        entropy_server.close_repositories()

        return exit_st

    @staticmethod
    def push(entropy_server, repository):
        """
        Push staged packages in repository to online Entropy mirrors.
        """
        rc = PackageBuilder._push_packages(entropy_server, repository)
        if rc != 0:
            return rc
        rc = PackageBuilder._push_repository(entropy_server, repository)
        return rc

    @staticmethod
    def _push_packages(entropy_server, repository):
        """
        Upload newly built packages.
        """
        mirrors_tainted, mirrors_errors, successfull_mirrors, \
            broken_mirrors, check_data = \
                entropy_server.Mirrors.sync_packages(
                    repository, ask = False, pretend = False)
        if mirrors_errors and not successfull_mirrors:
            return 1
        return 0

    @staticmethod
    def _push_repository(entropy_server, repository):
        """
        Update remote repository.
        """
        sts = entropy_server.Mirrors.sync_repository(repository)
        return sts



if __name__ == "__main__":

    ENV_VARS_HELP = """\

Environment variables for Package Builder module:
%s       =  repository identifier
%s    =  alternative command used to sync Portage
                              default: %s
%s   =  alternative command used to sync Portage overlays
                              default: %s
%s  = custom emerge arguments
                              default: %s

Environment variables passed to --post executables:
%s        = exit status from previous execution phases, useful for detecting
                             execution errors.

Environment variables passed to --pkgpre/--pkgpost executables:
%s       = name of the package that would be built

""" % (
        purple("MATTER_REPOSITORY_ID"),
        purple("MATTER_PORTAGE_SYNC_CMD"),
        darkgreen(PackageBuilder.DEFAULT_PORTAGE_SYNC_CMD),
        purple("MATTER_OVERLAYS_SYNC_CMD"),
        darkgreen(PackageBuilder.DEFAULT_OVERLAYS_SYNC_CMD),
        purple("MATTER_PORTAGE_BUILD_ARGS"),
        darkgreen(PackageBuilder.DEFAULT_PORTAGE_BUILD_ARGS),
        purple("MATTER_EXIT_STATUS"),
        purple("MATTER_PACKAGE_NAME"),)

    parser = argparse.ArgumentParser(
        description='Automated Portage Package Builder',
        epilog=ENV_VARS_HELP,
        formatter_class=argparse.RawDescriptionHelpFormatter)

    # * instead of + in order to support --sync only tasks
    parser.add_argument("spec", nargs='+', metavar="<spec>", type=file,
        help="matter spec file")

    parser.add_argument("--blocking",
        help="when trying to acquire Entropy Server locks, block until success",
        action="store_true")

    parser.add_argument("--commit",
        help="commit built packages to repository",
        action="store_true")

    parser.add_argument("--community",
        help="enforce Community Repository mode on Entropy Server",
        action="store_true")

    parser.add_argument("--debug",
        help="print debug output",
        action="store_true")

    parser.add_argument("--gentle",
        help="do not run if staged packages are present in Entropy repository",
        action="store_true")

    parser.add_argument("--pre", metavar="<exec>", type=file,
        help="executable to be called once for setup purposes",
        default=None)

    parser.add_argument("--post", metavar="<exec>", type=file,
        help="executable to be called once for teardown purposes",
        default=None)

    parser.add_argument("--push",
        help="push entropy package updates to online repository (only if --commit)",
        action="store_true")

    parser.add_argument("--sync",
        help="sync Portage tree, and attached overlays, before starting",
        action="store_true")

    try:
        nsargs = parser.parse_args(sys.argv[1:])
    except IOError as err:
        print dir(err)
        if err.errno == errno.ENOENT:
            sys.stderr.write(err.strerror + ": " + err.filename + "\n")
            raise SystemExit(1)
        raise

    if os.getuid() != 0:
        # root access required
        print_error("superuser access required")
        raise SystemExit(1)

    if nsargs.community:
        etpConst['community']['mode'] = True

    if nsargs.debug:
        print_warning(repr(nsargs))
        # if just one, drop from argv, so that it doesn't interfere with
        # entropy --debug support
        if sys.argv.count("--debug") < 2:
            etpUi['debug'] = False

    # parse spec files
    specs = []
    for spec_f in nsargs.spec:
        spec = SpecParser(spec_f)
        data = spec.parse()
        if data:
            specs.append(data)

    if not specs:
        print_error("invalid spec files provided")
        raise SystemExit(1)

    entropy_server = None
    exit_st = 0
    cwd = os.getcwd()
    # This application doesn't like implicit inteactivity
    etpUi['interactive'] = False

    try:
        try:
            entropy_server = get_entropy_server(etpConst['community']['mode'])
        except PermissionDenied:
            # repository not available or not configured
            print_error("no valid server-side repositories configured")
            raise SystemExit(3)

        # validate repository entries of spec metadata
        avail_repos = entropy_server.repositories()
        for spec in specs:
            if spec["repository"] not in avail_repos:
                print_error("invalid repository %s" % (spec["repository"],))
                raise SystemExit(10)

        if nsargs.blocking:
            print_info("--blocking enabled, please wait for locks...")

        with EntropyResourceLock(entropy_server, nsargs.blocking):

            if nsargs.gentle:
                # check if there is something to do
                to_be_added, to_be_removed, to_be_injected = \
                    entropy_server.scan_package_changes()
                if to_be_added: # only check this, others we can ignore
                    to_be_added = [x[0] for x in to_be_added]
                    to_be_added.sort()
                    print_error("--gentle specified, and unstaged packages found:")
                    for name in to_be_added:
                        print_warning("  " + name)
                    raise SystemExit(5)

                # also check for uncommitted configuration files changed
                problems = entropy_server._check_config_file_updates()
                if problems:
                    print_error(
                        "some configuration files have to be merged manually")
                    raise SystemExit(6)

                preserved_libs = \
                    PackageBuilder.check_preserved_libraries()
                if preserved_libs:
                    print_error(
                        "preserved libraries are found on system, aborting.")
                    raise SystemExit(7)

            # setup
            if nsargs.pre:
                rc = PackageBuilder.setup(nsargs.pre, cwd)
                if rc != 0:
                    exit_st = rc

            if exit_st == 0:

                if nsargs.sync:
                    rc = PackageBuilder.sync()
                    if rc != 0:
                        exit_st = rc

                if exit_st == 0:
                    completed = []
                    tainted_repositories = set()
                    preserved_libs_error = False
                    for spec in specs:

                        keep_going = spec.get("keep-going", "no") == "yes"
                        local_completed = []

                        for package in spec["packages"]:
                            builder = PackageBuilder(entropy_server, package,
                                spec)
                            rc = builder.run()
                            preserved_libs = \
                                PackageBuilder.check_preserved_libraries()
                            if preserved_libs:
                                # abort, library breakages detected
                                exit_st = 1
                                print_error(
                                    "preserved libraries detected, aborting")
                                preserved_libs_error = True
                                break

                            if rc == 0:
                                local_completed.append(package)
                                tainted_repositories.add(spec["repository"])
                            elif rc < 0:
                                # ignore warning and go ahead
                                continue
                            else:
                                exit_st = rc
                                if not keep_going:
                                    break

                        if preserved_libs_error:
                            # completely abort
                            break

                        completed.extend(local_completed)
                        # portage calls setcwd()
                        os.chdir(cwd)

                        if local_completed and nsargs.commit:
                            rc = PackageBuilder.commit(entropy_server,
                                spec["repository"], local_completed)
                            if exit_st == 0 and rc != 0:
                                exit_st = rc
                                if not keep_going:
                                    break

                    if tainted_repositories and nsargs.push and nsargs.commit \
                            and not preserved_libs_error:
                        for repository in tainted_repositories:
                            rc = PackageBuilder.push(entropy_server,
                                repository)
                            if exit_st == 0 and rc != 0:
                                exit_st = rc

            if nsargs.post:
                rc = PackageBuilder.teardown(nsargs.post, cwd,
                    exit_st)
                if exit_st == 0 and rc != 0:
                    exit_st = rc

    except EntropyResourceLock.NotAcquired:
        print_error("unable to acquire Entropy Resources lock")
        raise SystemExit(42)
    except KeyboardInterrupt:
        print_error("Keyboard interruption")
        raise SystemExit(100)
    finally:
        if entropy_server is not None:
            entropy_server.shutdown()

    print_warning("")
    print_warning("")
    print_warning("Tasks complete, exit status: %d" % (exit_st,))
    raise SystemExit(exit_st)
